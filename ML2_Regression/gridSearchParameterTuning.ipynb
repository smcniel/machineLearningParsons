{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sal = pd.read_csv('./data/mergedSalary2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eliminate rows with missing Y values (NaN)\n",
    "sal['missingSalary'] = pd.isnull(sal['salary'])\n",
    "sal2 = sal[(sal.missingSalary == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of X vars to include\n",
    "X_numeric_features = ['sup1', 'sup2',\n",
    "                      'sup3', 'sup4', \n",
    "                      'sup5', 'yearsinposition',\n",
    "                      'yearsinprofession', 'age',\n",
    "                      'inst1', 'inst2', 'inst3', \n",
    "                      'inst4', 'inst5', 'instbudget', \n",
    "                      'instsize', 'total_population',\n",
    "                      'median_household_income', \n",
    "                      'no_male_hs', 'no_female_hs', \n",
    "                      'no_hs', 'at_least_hs_male', \n",
    "                      'at_least_hs_female', 'at_least_hs', \n",
    "                      'hs_some_college_male', 'hs_some_college_female',\n",
    "                      'hs_some_college', 'bachelors_male', \n",
    "                      'bachelors_female', 'bachelors',\n",
    "                      'graduate_male', 'graduate_female', \n",
    "                      'graduate', 'hispanic', 'white',\n",
    "                      'black', 'native_american', 'asian_api', \n",
    "                      'two_race_or_more', 'male_unemployment', \n",
    "                      'female_unemployment', 'renter', 'owner', \n",
    "                      'median_rent', 'Sex.by.Age..Male.',\n",
    "                      'Sex.by.Age..Female.', 'full_time', \n",
    "                      'part_time', 'foreign_born', 'US_born', \n",
    "                      'married', 'divorced', 'poverty']\n",
    "X_numeric = sal2[X_numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dummy variables for each of the categorical features\n",
    "# DOC: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n",
    "\n",
    "X_categorical_features = ['function', 'gender', 'race', \n",
    "                          'highestdegree', 'category', 'insttype',\n",
    "                          'city', 'state']\n",
    "X_categorical = sal2[X_categorical_features]\n",
    "\n",
    "function_dummies = pd.get_dummies(X_categorical['function'])\n",
    "gender_dummies = pd.get_dummies(X_categorical['gender'])\n",
    "race_dummies = pd.get_dummies(X_categorical['race'])\n",
    "highestDegree_dummies = pd.get_dummies(X_categorical['highestdegree'])\n",
    "category_dummies = pd.get_dummies(X_categorical['category'])\n",
    "instType_dummies = pd.get_dummies(X_categorical['insttype'])\n",
    "city_dummies = pd.get_dummies(X_categorical['city'])\n",
    "state_dummies = pd.get_dummies(X_categorical['state'])\n",
    "\n",
    "# convert to ndarray\n",
    "X_dummy_features = pd.concat([function_dummies, gender_dummies, \n",
    "                              race_dummies, highestDegree_dummies, \n",
    "                              category_dummies, instType_dummies, \n",
    "                              city_dummies, state_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing values in numerical features\n",
    "# DOC: http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer()\n",
    "imp.fit(X_numeric)\n",
    "X_numeric_imputed = imp.transform(X_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate dummy and imputed numeric for X\n",
    "\n",
    "X = np.concatenate((X_dummy_features, X_numeric_imputed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y is salary\n",
    "y = sal2.loc[:, ['salary']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets \n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([10, 1, 0.8, 0.6, 0.1, 0.01, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([ 10.  ,   1.  ,   0.8 ,   0.6 ,   0.1 ,   0.01,   0.  ])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.737924469413\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "X_train_no_intercept = X_train\n",
    "X_train = X_train.reshape(-1, X_train.shape[1])\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print and summarize the results of the grid search\n",
    "print(grid)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
